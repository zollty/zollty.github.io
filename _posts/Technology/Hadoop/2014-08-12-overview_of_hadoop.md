---
layout: post
title: 我对Hadoop的认识
category: 技术
tags: Hadoop
keywords: Hadoop 大数据 原理
---

## 前言 ##

学习Hadoop已经快半年了，中间断断续续，一直没有找到Hadoop相关的工作机会，只是自己靠兴趣在学，感觉掌握的非常有限。因为没有实践，别人尤其是面试官问起来时经常感觉底气不足，在这里记录下我对Hadoop的一点理解，也算是对半年学习的一个小结。

本文档是我想一点写一点，未完待续，欢迎和大家一起探讨!

## Hadoop是什么 ##
上半年参加阿里的面试，临到最后，面试官问我：“你既然学了Hadoop，那你把我当成对Hadoop一点都不了解的人，你怎么给我讲Hadoop？”我当时说：“Hadoop类似于一个操作系统，无非是传统的操作系统只管理一台机器，而它能管理多台机器。”当时Hadoop2.x还没有出来，这样的回答不太合适。Hadoop2.x出来后，Hadoop拥有自己的文件系统HDFS和资源管理组件YARN，这么说就有一点味道了。

笔者最近在学习Ganglia，这是一个分布式的监控软件，可以监控一个集群的各项参数，当然也可以用来监控Hadoop集群。有了两个学习分布式软件的经历，回过头看，hadoop作为一个分布式软件，种种机制就理所当然了。那么运行在多台机器上的分布式软件，一般有哪些共同点呢？

- 分为主节点和从节点。

	主节点负责和用户交互，从节点负责收集所在主机信息并汇报给主节点，接受并执行主节点的指令。
- 如何通信。
  
    这个大体分为两类：“主节点轮询从节点”和“从节点主动向主节点汇报（也叫发送心跳）”。因为要相互通信，所以主节点和从节点都会运行一个守护进程，用来接受和发送数据。除此之外，对于进程间交互，hadoop用到了RPC机制，这对了解hadoop的机理非常重要。
- 可以容错。
  
    都预设集群中可能会有主机down掉，并提出方案来解决这个问题。
- 动态扩展。
  
    可以根据需求增加和减少节点。

## Hadoop的组成 ##

- 本质
	
	“存储”分散到多台主机上，“计算”分散到多台主机上
- 问题
	
	分散到哪台主机上？如何分散，处理？化整为零后，如何化零为整？

首先谈一下hadoop是干什么的，简单点说，hadoop是处理大数据的，处理大数据，首先要能存储这么大数据。可一台主机存不下，那就需要多台。一个文件存在多个主机上，增删改查，一大堆问题。我们要屏蔽掉这些问题，于是Hadoop有了HDFS，它对外提供一个文件系统抽象，我们只管增删改查文件，其他的问题它来解决。

存储搞定后，就是处理文件中的数据，传统的方式是文件跟着程序走。即先将文件读入程序所运行主机的内存，处理，然后写到磁盘上。这是一套串行的操作，可一是没那么大的内存，就算有，将文件从磁盘加载到内存中，所费时间黄花菜都凉好几回了。

在新的处理方式下，文件分布在多台机器上，我们程序跟着文件走（要知道我们的节点都有计算能力，不用白不用喔）。将程序传送到文件所在的“主机们”上，然后同时运行，汇总结果，输出。这是一套并行化的流程，这里有三个问题：

- 不是所有串行都能并行化

	并行化要求所处理的数据之间没有关系，处理的先后顺序没有关系。
- 所写代码已经完全不是一个套路
	
	- 数据在处理之前位于不同的节点，每个节点的数据之间存在一定的联系，处理之前要消除这种联系

	- 每个节点处理完毕后，要有汇总和善后工作

	- 某个并行节点可能会运行失败，要发现这种失败并进行处理

- 谁来执行
	
	假设文件分散在5个节点上，我难道在这5个节点上都启动处理程序么？假设其中有几个很忙，根本没工夫呢？假设某个节点性能不行，根本就处理不了呢？于是问题来了，主节点需要对所管理节点是不是有空，每个节点能吃几碗干饭都有所了解，然后启动合适的多个节点进行处理任务。
    
## HDFS ##

整体结构如下：

主节点运行Namenode，从节点运行Datanode。

HDFS数据分为两类：文件目录结构，文件数据本身。

分工如下：

Namenode存储meta数据：文件系统目录结构和文件和所包含块的映射关系。

Datanode数据存储文件数据块本身，一个Datanode存储哪些块由datanode启动时向namenode汇报（safemode概念）。

这类似于linux的索引块和一般磁盘块，文件在磁盘中也不是连续存储的，类比一下，道理都是一样的。文件系统嘛，就是完成从文件名（路径）到数据块的映射。（数据库管理系统，完成从记录到磁盘块的映射）


除Namenode和Datanode外，HDFS还有一个重要节点：SecondaryNamenode，详情如下：
Namenode为高效访问数据 ==> 
将meta信息存入内存 ==> 
内存数据易丢失 ==> 
将内存信息周期性备份成fsimage文件 ==> 
备份和内存数据不同步 ==> 
两次备份之间记录日志edits ==> 
需要合并fsimage和edits，namenode没空 ==> 
SecondaryNamenode负责这个工作


## YARN ##
整体结构：主节点ResourceManager，从节点NodeManager

在hadoop2.x版本中，提出了新的组件Yarn，ResourceManager通过NodeManager感知节点的能力和状态，以便分派。

ApplicationMaster代表一个job，和ResourceManager要资源，和NodeManager协作完成工作。

## MapReduce思路 ##

现如今，Hadoop还可以选择其它计算模型。

MapReduce，在Hadoop中，整个过程分为六个阶段，主要是map和reduce两个过程。

我们提到，程序跟着文件走，然后存储该文件数据的节点同时运行，最后汇总，输出。但是，A节点该文件块对应的某些数据和B节点的数据有关系，要一块处理。于是，处理之前，要先把所有相关的数据拢到一块，再分别处理。then，处理过程一分为二：

- Map：先将数据归类，相同特征的数据（或需要一起处理的数据）放一个节点；
- Reduce：此时节点之间的数据没有瓜葛了，进行处理。（数据归类好后，持久化存储起来是不是更好？）

关于Map和Reduce过程，有一个很形象的比喻，那就是SQL中的group by语句和聚集函数。

`select count(*) from student group by sex`，

该SQL用来计算student表中男女生的人数，总要先将男生和女生从人群中拉出来，站两堆，才数的过来。这里，group by对应map过程，count对应reduce过程。

这里，六大阶段不再赘述，但每个阶段我们都可以个性化，以满足不同的业务需求。

## 其它 ##

- 主节点负责响应请求，实际的实施还是由客户端和从节点交互完成的

	- FileSystem从namenode得到文件块所在的datanode后，和datanode交互读取数据
	- ApplicationMaster从ResourceManager要到资源后，和NodeManager交互完成计算过程